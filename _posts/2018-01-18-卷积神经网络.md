---
layout: post
title: '卷积神经网络实例'
date: 2018-01-18
author: MrXuyc
categories: 技术
cover: '/assets/img/tensorflow/tensorflow1.jpg'
tags: 神经网络
---
> 卷积神经网络

## 卷积神经网络

![](/assets/img/tensorflow/data/cnn/1.png)

![](/assets/img/tensorflow/data/cnn/2.png)

### 核心概念
将原始图像分成很多个小块，一个块提取出代表的特征向量。

![](/assets/img/tensorflow/data/cnn/3.jpg)

一个小块可以提取多少个代表？ 根据filter函数 定义， filter的个数决定了这个特征图立体的高度  高维特征  filter内部的不同提取出不同的变量。 filter的规格和原始数据的小块规格是相同的

不断的conv refu 

![](/assets/img/tensorflow/data/cnn/4.jpg)

计算过程   每个区域提取一个特征值 根据将不同的通道取和汇总 再 wx+b 公式进行计算


```
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.examples.tutorials.mnist import input_data

# 读取MNIST数据
mnist = input_data.read_data_sets("data", one_hot = True)
trainimg = mnist.train.images
traimlabel = mnist.train.labels
testimg = mnist.test.images
testlabel = mnist.test.labels
print("MNIST READY!")

n_input = 784

n_output = 10
# 创建占位符，之后一个batch一个batch往里传入
x = tf.placeholder(tf.float32, [None, n_input])
y = tf.placeholder(tf.float32, [None, n_output])
# dropout比例，保留的比例
keepratio = tf.placeholder(tf.float32)


# 权重项
weights = {
    # 卷积层的深度要与数据的深度保持一直   灰度图片深度为1
    # 卷积层初始化                        h   w   输入深度  output(64张特征图)
    "wc1" : tf.Variable(tf.random_normal([3, 3, 1, 64], stddev = 0.1)),
    #                                              输入深度（64个特征图）   output(128张特征图)
    "wc2" : tf.Variable(tf.random_normal([3, 3, 64, 128], stddev = 0.1)),
    #    poli层将图片像素降低  减少二分之一        128特征图                    
    "wd1" : tf.Variable(tf.random_normal([7*7*128, 1024], stddev = 0.1)),
    "wd2" : tf.Variable(tf.random_normal([1024, n_output], stddev = 0.1))
}
# 偏执项   多少个输出output
biases = {
    "bc1" : tf.Variable(tf.random_normal([64], stddev = 0.1)),
    "bc2" : tf.Variable(tf.random_normal([128], stddev = 0.1)),
    "bd1" : tf.Variable(tf.random_normal([1024], stddev = 0.1)),
    "bd2" : tf.Variable(tf.random_normal([n_output], stddev = 0.1))
}

def conv_basic(_input, _w, _b, _keepratio):
    #input  reshape对参数进行预处理  [ n  h  w  c]  n 为-1让tensorflow推断  c灰度 为1
    _input_r = tf.reshape(_input, shape=[-1, 28, 28, 1])
    #卷积 nn.conv2d                            strides  四维  [ n  h  w  c] 对应的strides   hw一般同步改动
    # padding SAME  不足补0  VALID  不填冲
    _conv1 = tf.nn.conv2d(_input_r, _w["wc1"], strides=[1,1,1,1], padding="SAME")
    # 激活函数 relu
    _conv1 = tf.nn.relu(tf.nn.bias_add(_conv1, _b["bc1"]))
    # 池化层  ksize 多大的区域window_size进行  
    _pool1 = tf.nn.max_pool(_conv1, ksize=[1,2,2,1], strides=[1,2,2,1],padding="SAME")
    # dropout 随机杀死节点    _keepratio 保留比例
    _pool_dr1 = tf.nn.dropout(_pool1, _keepratio)

    _conv2 = tf.nn.conv2d(_pool_dr1, _w["wc2"], strides=[1,1,1,1], padding="SAME")

    _conv2 = tf.nn.relu(tf.nn.bias_add(_conv2, _b["bc2"]))

    _pool2 = tf.nn.max_pool(_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding="SAME")

    _pool_dr2 = tf.nn.dropout(_pool2, _keepratio)
    #转换成向量模式     全连接层
    _dense1 = tf.reshape(_pool_dr2, [-1, _w["wd1"].get_shape().as_list()[0]])

    _fc1 = tf.nn.relu(tf.add(tf.matmul(_dense1, _w["wd1"]), _b["bd1"]))

    _fc_dr1 = tf.nn.dropout(_fc1, _keepratio)

    _out = tf.add(tf.matmul(_fc_dr1, _w["wd2"]), _b["bd2"])

    out = {'input_r': _input_r, 'conv1': _conv1, 'pool1': _pool1, 'pool_dr1': _pool_dr1,
          'conv2': _conv2, 'pool2': _pool2, 'pool_dr2': _pool_dr2, 'dense1': _dense1,
          'fc1': _fc1, 'fc_dr1': _fc_dr1, 'out': _out}

    return out

print("CNN READY")

# 计算图op定义

pred = conv_basic(x, weights, biases, keepratio)["out"]

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = pred))

optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)

corr = tf.equal(tf.argmax(pred, 1),tf.argmax(y, 1))

accr = tf.reduce_mean(tf.cast(corr, tf.float32))

# 模型保存参数
# 每隔几次epoch进行保存
save_step = 1
# 指定max_to_keep 表示只保存最后三组模型

saver = tf.train.Saver(max_to_keep=3)

print("FUNCTION READY")
# 是否训练  1 使用数据训练  0 读取模型进行预测
do_train = 1
# 1个epoch白哦是所有数据跑一遍
training_epochs = 10

batch_size = 16

display_step = 1

with tf.Session() as sess:
    if do_train == 1:
        sess.run(tf.global_variables_initializer())

        for epoch in range(training_epochs):
            # 平均损失值
            avg_cost = 0
            # 总batch个数：数据总数比上每个batch的数据数量
            # total_batch = int(trainimg.shape[0] / batch_size)
            # 这里为了跑的快一些示范直接定义为一个较小的值
            total_batch = 10
            # 迭代每个batch
            for i in range(total_batch):
                batch_xs , batch_ys = mnist.train.next_batch(batch_size)
                sess.run(optm, feed_dict={x: batch_xs,y:batch_ys, keepratio: 0.7})
                avg_cost +=sess.run(cost, feed_dict={x:batch_xs,y:batch_ys, keepratio: 1.})
            avg_cost = avg_cost / total_batch

            # 展示

            if epoch % display_step == 0 :
                print ('Epoch:%03d/%03d cost:%.9f' % (epoch, training_epochs, avg_cost))
                # 训练集正确率
                train_acc = sess.run(accr, feed_dict={x: batch_xs, y: batch_ys, keepratio: 1.})
                # 测试集正确率
                test_acc = sess.run(accr, feed_dict={x: mnist.test.images, y: mnist.test.labels, keepratio:1.})
                print ('train accuracy : ', train_acc, ',test accuracy:', test_acc)
            # 模型保存
            if epoch % save_step == 0:
                saver.save(sess, 'save/nets/cnn_mnist_basic.ckpt-' + str(epoch))
        print ('FINISHED')

    if do_train == 0:
        epoch = training_epochs-1
        saver.restore(sess, 'save/nets/cnn_mnist_basic.ckpt-' + str(epoch))
        ttest_acc = sess.run(accr, feed_dict={x: mnist.test.images, y: mnist.test.labels, keepratio:1.})
        print ('train accuracy : ', train_acc, ',test accuracy:', test_acc)



```
