---
layout: post
title: '神经网络基础知识'
date: 2018-01-16
author: MrXuyc
categories: 技术
cover: '/assets/img/tensorflow/tensorflow1.jpg'
tags: 神经网络
---
> 神经网络基础知识

## 得分函数

通过权重计算的分数。

## 损失函数

预期值和实际值的误差。

### 惩罚项

解决损失函数相同，如何选择。

## 前向传播流程

得分函数，指数映射，归一化。进行求-log()  (softmax)
梯度下降，求最优化。损失函数最低点。

## 神经网络步骤

前向传播，后向传播，参数调优。

## batchsize

防止由于个别错误数据导致模型函数的错误推到，故每次处理batchsize数据，求size整体对模型函数的影响

## 反向传播

通过最后的输出，求偏导。计算之前的变量可对其产生影响的权重。加法门单元，1。max门单元，取最大。乘法门单元，互换的感觉。其中要遵循从后向前依次求导。用累乘的形式。

## 神经网络特点

层次结构。激活函数用于线性到非线性的转换。sigmoid函数，取值范围0-1。

## 神经网络注意项

神经网络，神经元数量要尽可量偏多，会对于结果更好。防止过拟合化

## drop-out

每次迭代中随机去除一定的元素，防止过拟合。比率一般在0.4-0.6之间

数据预处理，零中心化（减均值），均值化 （除标准差） 。

## 过拟合

防止过拟合化，需要进行正则惩罚力度，过拟合化会让会让神经网络学习到错误数据离群数据导致在真实预测时出现错误，应该让分界线平滑更好。

越多的神经元能够描述越复杂的模型，但是越多神经元过拟合化的风险会增大

## 梯度下降

为了防止梯度下降法，梯度会近为0，需要激活函数。主要是用relu很少用sigmoid
